{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.autograd import Variable\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class my_Dataset(Data.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.X = features\n",
    "        self.y = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "class WheelRailTrajectoryDataset:\n",
    "    def __init__(self,label=3):\n",
    "        standard_scaler = StandardScaler()\n",
    "        self.raw_data1 = pd.read_csv(\"../dataset/curve_R400.csv\")\n",
    "        self.raw_data2 = pd.read_csv(\"../dataset/curve_R1000.csv\")\n",
    "        self.raw_data3 = pd.read_csv(\"../dataset/curve_R2000.csv\")\n",
    "        self.raw_data4 = pd.read_csv(\"../dataset/curve_R3000.csv\")\n",
    "        self.raw_data5 = pd.read_csv(\"../dataset/curve_R4000.csv\")\n",
    "        self.raw_data6 = pd.read_csv(\"../dataset/curve_R5000.csv\")\n",
    "        self.raw_data = pd.concat([self.raw_data1,self.raw_data2,self.raw_data3,self.raw_data4,self.raw_data5,self.raw_data6])\n",
    "        self.label = label\n",
    "        #标准化\n",
    "        self.data = standard_scaler.fit_transform(self.raw_data)\n",
    "        self.mean = standard_scaler.mean_[label]\n",
    "        self.sd = math.sqrt(standard_scaler.var_[label])\n",
    "\n",
    "\n",
    "    def construct_set(self, train_por=0.6,val_por=0.2,test_por=0.2, window_size=100):\n",
    "        X = []\n",
    "        Y = []\n",
    "        list = [self.raw_data1.shape[0],self.raw_data2.shape[0],self.raw_data3.shape[0],self.raw_data4.shape[0],self.raw_data5.shape[0],self.raw_data6.shape[0]]\n",
    "        num = 0\n",
    "        for j in range(len(list)):\n",
    "            if j!=0:\n",
    "                num = num+list[j-1]\n",
    "            for i in range(list[j]-window_size):\n",
    "                seq = self.data[num+i:num+i+window_size+1]\n",
    "                X.append(seq[0:window_size,:self.label])\n",
    "                y = seq[window_size:window_size+1,self.label]\n",
    "                if(y>0.6 or y<-0.6):\n",
    "                    Y.append(1)\n",
    "                else:\n",
    "                    Y.append(0)\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        print(X.shape)\n",
    "        print(Y.shape)\n",
    "        train_x,test_x,train_y,test_y = train_test_split(X,Y,test_size=test_por,train_size=train_por+val_por,shuffle=True)\n",
    "        train_x,val_x,train_y,val_y =  train_test_split(train_x,train_y,test_size=val_por/(val_por+train_por),train_size=train_por/(val_por+train_por),shuffle=True)\n",
    "\n",
    "        train_set = my_Dataset(torch.Tensor(train_x), torch.Tensor(train_y))\n",
    "        val_set = my_Dataset(torch.Tensor(val_x), torch.Tensor(val_y))\n",
    "        test_set = my_Dataset(torch.Tensor(test_x), torch.Tensor(test_y))\n",
    "        return train_set, val_set, test_set\n",
    "\n",
    "TrajectoryData = WheelRailTrajectoryDataset()\n",
    "train_set, val_set, test_set = TrajectoryData.construct_set()\n",
    "batch_size = 256\n",
    "train_loader = Data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
    "val_loader = Data.DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=True)\n",
    "test_loader = Data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbbdb9e2269c2895"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model,seq_len = 100):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(seq_len, d_model+1)\n",
    "        #维数 seq_len X d_model\n",
    "        position = torch.arange(0, seq_len).unsqueeze(1) #  维数 seq_lenX1\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        #维数 dmodel/2\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        #维数 seq_len X dmodel/2\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        #维数 1Xseq_lenXd_model\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x batch_size X seq_len X num_features\n",
    "        #print(\"x:\",x.shape)\n",
    "        #print(\"pe:\",self.pe.shape)\n",
    "        x = x + Variable(self.pe[:,:,:x.shape[-1]], requires_grad=False)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0d403e20238b602"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class IsometricConvBlock(nn.Module):\n",
    "    def __init__(self,input_dim,mlp_dim,input_length):\n",
    "        super().__init__()\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_dim, out_channels=mlp_dim,padding='same',kernel_size=1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(in_channels=mlp_dim, out_channels=input_dim,padding='same',kernel_size=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.norm_1 = nn.LayerNorm(input_dim)\n",
    "        self.norm_2 = nn.LayerNorm(input_dim)\n",
    "        #Conv1d要求输入为batch_size*features*seq_length\n",
    "        self.conv = nn.Conv1d(in_channels=input_dim, out_channels=input_dim,\n",
    "                              kernel_size=input_length,padding=0,stride=1,groups=3)\n",
    "    def isometric_conv(self,x):\n",
    "        #batch_size feature_size seq_len\n",
    "        zeros = torch.zeros((x.shape[0], x.shape[1], x.shape[2]-1),device='cuda')\n",
    "        x = torch.cat((zeros, x), dim=-1)\n",
    "        out = self.conv(x)\n",
    "        return out\n",
    "\n",
    "    def forward(self,x):\n",
    "        #input : batch_size seq_len feature_size\n",
    "        residual = x\n",
    "        x  = x.permute(0,2,1)\n",
    "        #batch_size feature_size seq_len\n",
    "        x = self.isometric_conv(x)\n",
    "        x = x.permute(0,2,1)\n",
    "        x = self.norm_1(x + residual)\n",
    "        residual = x\n",
    "        x = x.permute(0,2,1)\n",
    "        x = self.ffn(x)\n",
    "        x = x.permute(0,2,1)\n",
    "        out = self.norm_2(x + residual)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ff95740b0b83bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MICNet(nn.Module):\n",
    "    def __init__(self,num_i,feature_dim,mlp_dim,seq_len):\n",
    "        super().__init__()\n",
    "        self.pe = PositionalEncoding(3)\n",
    "        self.IsometricConvList = nn.ModuleList([IsometricConvBlock(feature_dim,mlp_dim,seq_len) for _ in range(num_i)])\n",
    "        self.channel_interaction = nn.Sequential(\n",
    "            nn.Linear(in_features=feature_dim,out_features=feature_dim*16),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(in_features=feature_dim*16,out_features=1),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=seq_len,out_features=seq_len//2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(in_features=seq_len//2,out_features=2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(feature_dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x+self.pe(x)\n",
    "        residual = x\n",
    "        for Iblock in self.IsometricConvList:\n",
    "            i_features = Iblock(x)\n",
    "        i_features = self.norm(i_features+residual)\n",
    "        y = self.channel_interaction(i_features).squeeze()\n",
    "        y = self.classifier(y)\n",
    "        return y"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edb4d5a65983dcc8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
